% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}
\usepackage{standalone}
\usepackage{color}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}


\begin{document}
%
\title{Admission Handler}

\author{Group 18: Jan Haas \and Simon Hauser \and Samuel Kenworthy}

\institute{}
%
\maketitle              % typeset the header of the contribution

\section{Introduction}
This project implements a distributed admission system for large events and venues with limited capacity.
The stream of visitors entering or exiting the venue will be monitored in real-time via devices at each entrance.
Live feedback will be provided to each device, enabling organizers to stop admission when the maximum capacity of the venue has been reached.

As the world starts to reopen after the pandemic and public events become possible again, systems are required to handle the keeping of safe capacities, in-line with changing guidelines and laws.
Pre-selling tickets is one possibility of managing these limits, yet events such as Christmas markets, beer gardens and public concerts live off spontaneous visits.
This project will enable the simple monitoring and managing of such streams of visitors, by providing a dynamically scalable system.

\section{Requirements Analysis}

\input{mrequirement_analysis}

\newpage
\section{Architecture}
%The system is modeled in a single network with at least a machine running multiple clients and at least two running some servers each.
%Both participant types will be written in Python.\\
\begin{figure}
\includegraphics[width=\textwidth]{Architecture_Diagram_new.png}
\end{figure}
\subsection{Demo Setup}
For the demo, we will run several servers and clients on 2+ laptops to ensure a realistic scenario.
Additionally, we implemented both a simple GUI wrapper that can interact with a single client, as well as a demo observer that summarizes the current state of the system.
\section{Implementation Details}
We decided to complete the project using purely Python.
\input{group_management}

\input{leader_election}

\input{multicast}

\input{byzantine}

\input{client}

\input{monitoring}
\newpage
\section{Code}
We will have sent invitations to our private code repository on github by the time this report is read.

\section{Discussion and Conclusion}
Working on this project definitely made clear that just a very simple application requires a large amount of effort before it can be safely ran in a distributed way, even though we already ignored the aspect of security.
\\\\
For basic functionality up to algorithms we used for voting, finding a consensus etc. we had to make additional considerations for cases such as members or message recipients becoming unreachable mid-process and decide on how to best handle them.
Quite often, we would find new edge cases during later tests and had to then deal with them before making sure to reproduce them correctly during further tests to ensure we fixed them.
Additionally, even locating a fault often proved much more complex than when dealing with a local or at least monolithic system, often requiring us to log all messages received by the different system components.

On the other hand, as our group view is managed by (missed) heart beats, it can take a visible amount of time for it to update.
This also means that at times, multicast messaging stalls until everything is sorted out again.
Additionally, tests with eight or more servers clearly showed the limitations of the byzantine algorithm, as its exponential message complexity floods the multicast channel, stalling the system as well.
\\\\
All in all, the experience gained from this project should help us make better decisions not only when developing system components actually concerned with distribution, but also when developing components that will run in a distributed system and should thus be ready to deal with faults not present in a monolithic system.
\end{document}
